{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "DATA_DIR = Path(\".\")"
      ],
      "metadata": {
        "id": "fOaP9bgKDeJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR / \"test.csv\")\n",
        "sample = pd.read_csv(DATA_DIR / \"sample_submission.csv\")\n",
        "if \"Unnamed: 0\" in train.columns:\n",
        "    train = train.rename(columns={\"Unnamed: 0\": \"id\"})\n",
        "\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Test shape:\", test.shape)"
      ],
      "metadata": {
        "id": "JmDH1Y2VDiA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"period_start_dt\"] = pd.to_datetime(\n",
        "    train[\"period_start_dt\"], format=\"%Y-%m-%d\", errors=\"coerce\"\n",
        ")\n",
        "test[\"period_start_dt\"] = pd.to_datetime(\n",
        "    test[\"period_start_dt\"], format=\"%d.%m.%Y\", errors=\"coerce\"\n",
        ")\n",
        "\n",
        "for df_ in (train, test):\n",
        "    df_[\"series_id\"] = (\n",
        "        df_[\"product_rk\"].astype(str) + \"_\" + df_[\"store_location_rk\"].astype(str)\n",
        "    )"
      ],
      "metadata": {
        "id": "6zqq9SXMDnNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "promo_mode = (\n",
        "    train[\"PROMO1_FLAG\"].mode().iloc[0]\n",
        "    if \"PROMO1_FLAG\" in train.columns\n",
        "    else 0\n",
        ")\n",
        "train[\"PROMO1_FLAG\"] = train.get(\"PROMO1_FLAG\", promo_mode).fillna(promo_mode)\n",
        "if \"PROMO1_FLAG\" in test.columns:\n",
        "    test[\"PROMO1_FLAG\"] = test[\"PROMO1_FLAG\"].fillna(promo_mode)\n",
        "else:\n",
        "    test[\"PROMO1_FLAG\"] = promo_mode\n",
        "\n",
        "base_cols = [\n",
        "    \"PRICE_REGULAR\",\n",
        "    \"PRICE_AFTER_DISC\",\n",
        "    \"AUTORIZATION_FLAG\",\n",
        "    \"PROMO2_FLAG\",\n",
        "    \"NUM_CONSULTANT\",\n",
        "]\n",
        "\n",
        "for col in base_cols:\n",
        "    if col in train.columns:\n",
        "        train[col] = train.groupby([\"product_rk\", \"store_location_rk\"])[col].transform(\n",
        "            lambda s: s.ffill().bfill()\n",
        "        )\n",
        "        prod_med = train.groupby(\"product_rk\")[col].transform(\"median\")\n",
        "        train[col] = train[col].fillna(prod_med)\n",
        "        prod_med_map = train.groupby(\"product_rk\")[col].median().to_dict()\n",
        "        test[col] = test[\"product_rk\"].map(prod_med_map).fillna(0.0).values\n",
        "    else:\n",
        "        test[col] = 0.0\n"
      ],
      "metadata": {
        "id": "UNNOBjoIDpUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = sample[[\"id\"]].merge(test, on=\"id\", how=\"left\")\n",
        "\n",
        "test[\"product_rk\"] = (\n",
        "    test[\"product_rk\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        ")\n",
        "test[\"store_location_rk\"] = (\n",
        "    test[\"store_location_rk\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        ")\n",
        "test[\"series_id\"] = (\n",
        "    test[\"product_rk\"].astype(str) + \"_\" + test[\"store_location_rk\"].astype(str)\n",
        ")"
      ],
      "metadata": {
        "id": "ZjocuwIVDu_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_cols = [\"product_rk\", \"store_location_rk\", \"period_start_dt\"]\n",
        "test_new = test.merge(\n",
        "    train[key_cols].drop_duplicates().assign(_in_train=1),\n",
        "    on=key_cols,\n",
        "    how=\"left\",\n",
        ")\n",
        "test_new = test_new[test_new[\"_in_train\"].isna()].drop(columns=[\"_in_train\"])\n",
        "\n",
        "df = pd.concat([train, test_new], sort=False).reset_index(drop=True)\n",
        "df = df.sort_values([\"series_id\", \"period_start_dt\"]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "AA4HENNmDyKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"week\"] = df[\"period_start_dt\"].dt.isocalendar().week.astype(\"Int64\")\n",
        "df[\"month\"] = df[\"period_start_dt\"].dt.month.astype(\"Int64\")\n",
        "df[\"weekday\"] = df[\"period_start_dt\"].dt.weekday.astype(\"Int64\")\n",
        "df[\"year\"] = df[\"period_start_dt\"].dt.year.astype(\"Int64\")\n",
        "\n",
        "df[\"week_sin\"] = np.sin(2 * np.pi * df[\"week\"] / 52.0)\n",
        "df[\"week_cos\"] = np.cos(2 * np.pi * df[\"week\"] / 52.0)"
      ],
      "metadata": {
        "id": "aedZAREoD0jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"demand\"] = df[\"demand\"].astype(float)\n",
        "df[\"demand_log\"] = np.log1p(df[\"demand\"].clip(lower=0))\n",
        "\n",
        "df[\"demand_rel\"] = (\n",
        "    df.groupby(\"series_id\")[\"demand\"]\n",
        "    .pct_change()\n",
        "    .replace([np.inf, -np.inf], 0)\n",
        "    .fillna(0)\n",
        ")"
      ],
      "metadata": {
        "id": "OStp0dVlD4NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lags = [1, 2, 3, 4, 8, 12, 26, 52]\n",
        "\n",
        "for lag in lags:\n",
        "    df[f\"lag_{lag}\"] = df.groupby(\"series_id\")[\"demand\"].shift(lag)\n",
        "    df[f\"log_lag_{lag}\"] = df.groupby(\"series_id\")[\"demand_log\"].shift(lag)\n",
        "    df[f\"rel_lag_{lag}\"] = df.groupby(\"series_id\")[\"demand_rel\"].shift(lag)\n",
        "\n",
        "for w in [4, 8, 12]:\n",
        "    df[f\"roll_mean_{w}\"] = (\n",
        "        df.groupby(\"series_id\")[\"demand\"]\n",
        "        .shift(1)\n",
        "        .rolling(w, min_periods=1)\n",
        "        .mean()\n",
        "    )\n",
        "    df[f\"roll_median_{w}\"] = (\n",
        "        df.groupby(\"series_id\")[\"demand\"]\n",
        "        .shift(1)\n",
        "        .rolling(w, min_periods=1)\n",
        "        .median()\n",
        "    )\n",
        "    df[f\"rel_roll_mean_{w}\"] = (\n",
        "        df.groupby(\"series_id\")[\"demand_rel\"]\n",
        "        .shift(1)\n",
        "        .rolling(w, min_periods=1)\n",
        "        .mean()\n",
        "    )"
      ],
      "metadata": {
        "id": "_h0d1JLiD6AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"PRICE_REGULAR\" in df.columns and \"PRICE_AFTER_DISC\" in df.columns:\n",
        "    df[\"PRICE_REGULAR\"] = df[\"PRICE_REGULAR\"].replace(0, np.nan)\n",
        "    df[\"price_ratio\"] = df[\"PRICE_AFTER_DISC\"] / df[\"PRICE_REGULAR\"]\n",
        "    df[\"price_ratio\"] = (\n",
        "        df[\"price_ratio\"].replace([np.inf, -np.inf], 1.0).fillna(1.0)\n",
        "    )\n",
        "else:\n",
        "    df[\"price_ratio\"] = 1.0\n",
        "\n",
        "df[\"promo_discount\"] = df[\"PROMO1_FLAG\"] * (\n",
        "    1.0 - df[\"price_ratio\"].clip(upper=1.5)\n",
        ")\n",
        "\n",
        "df[\"promo_prev_mean_4\"] = (\n",
        "    df.groupby(\"series_id\")[\"PROMO1_FLAG\"]\n",
        "    .shift(1)\n",
        "    .rolling(4, min_periods=1)\n",
        "    .mean()\n",
        ")"
      ],
      "metadata": {
        "id": "7N_WmUCMD776"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series_stats = (\n",
        "    train.groupby(\"series_id\")[\"demand\"]\n",
        "    .agg([\"median\", \"mean\", \"count\"])\n",
        "    .rename(\n",
        "        columns={\n",
        "            \"median\": \"series_median\",\n",
        "            \"mean\": \"series_mean\",\n",
        "            \"count\": \"series_count\",\n",
        "        }\n",
        "    )\n",
        ")\n",
        "df = df.merge(series_stats, on=\"series_id\", how=\"left\")\n",
        "\n",
        "prod_stats = (\n",
        "    train.groupby(\"product_rk\")[\"demand\"]\n",
        "    .agg([\"median\", \"mean\"])\n",
        "    .rename(\n",
        "        columns={\n",
        "            \"median\": \"prod_median\",\n",
        "            \"mean\": \"prod_mean\",\n",
        "        }\n",
        "    )\n",
        ")\n",
        "df = df.merge(prod_stats, on=\"product_rk\", how=\"left\")\n",
        "\n",
        "global_med = train[\"demand\"].median()\n",
        "df[\"series_median\"] = df[\"series_median\"].fillna(global_med)\n",
        "df[\"series_mean\"] = df[\"series_mean\"].fillna(global_med)\n",
        "df[\"prod_median\"] = df[\"prod_median\"].fillna(global_med)\n",
        "df[\"prod_mean\"] = df[\"prod_mean\"].fillna(global_med)\n",
        "df[\"series_count\"] = df[\"series_count\"].fillna(0)"
      ],
      "metadata": {
        "id": "XZhE3exID-hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_fill_cols = [\n",
        "    \"month\",\n",
        "    \"weekday\",\n",
        "    \"week\",\n",
        "    \"year\",\n",
        "    \"week_sin\",\n",
        "    \"week_cos\",\n",
        "    \"PRICE_REGULAR\",\n",
        "    \"PRICE_AFTER_DISC\",\n",
        "    \"price_ratio\",\n",
        "    \"PROMO1_FLAG\",\n",
        "    \"PROMO2_FLAG\",\n",
        "    \"AUTORIZATION_FLAG\",\n",
        "    \"NUM_CONSULTANT\",\n",
        "    \"promo_prev_mean_4\",\n",
        "    \"promo_discount\",\n",
        "    \"series_median\",\n",
        "    \"series_mean\",\n",
        "    \"prod_median\",\n",
        "    \"prod_mean\",\n",
        "]\n",
        "\n",
        "lag_cols = (\n",
        "    [f\"lag_{l}\" for l in lags]\n",
        "    + [f\"log_lag_{l}\" for l in lags]\n",
        "    + [f\"rel_lag_{l}\" for l in lags]\n",
        "    + [f\"roll_mean_{w}\" for w in [4, 8, 12]]\n",
        "    + [f\"roll_median_{w}\" for w in [4, 8, 12]]\n",
        "    + [f\"rel_roll_mean_{w}\" for w in [4, 8, 12]]\n",
        ")\n",
        "\n",
        "feature_cols = base_fill_cols + lag_cols\n",
        "\n",
        "for c in feature_cols:\n",
        "    if c in df.columns:\n",
        "        df[c] = df.groupby(\"series_id\")[c].transform(\n",
        "            lambda s: s.ffill().bfill()\n",
        "        )\n",
        "        df[c] = df[c].fillna(df[\"prod_median\"])\n",
        "        df[c] = df[c].fillna(df[\"series_median\"])\n",
        "        df[c] = df[c].fillna(0.0)\n",
        "    else:\n",
        "        df[c] = 0.0"
      ],
      "metadata": {
        "id": "GVcUdrNUEAyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_proc = df[df[\"demand\"].notna()].copy()\n",
        "test_proc = df[df[\"demand\"].isna()].copy()\n",
        "\n",
        "print(f\"Processed: train rows {len(train_proc)}, test rows {len(test_proc)}\")\n",
        "\n",
        "X_all = train_proc[feature_cols].copy()\n",
        "y_all = train_proc[\"demand\"].astype(float)"
      ],
      "metadata": {
        "id": "pCfrZwyYEFVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_proc_sorted = train_proc.sort_values(\"period_start_dt\")\n",
        "split_date = train_proc_sorted[\"period_start_dt\"].quantile(0.85)\n",
        "\n",
        "mask_tr = train_proc_sorted[\"period_start_dt\"] < split_date\n",
        "mask_val = ~mask_tr\n",
        "\n",
        "X_tr = train_proc_sorted.loc[mask_tr, feature_cols]\n",
        "y_tr = train_proc_sorted.loc[mask_tr, \"demand\"].astype(float)\n",
        "\n",
        "X_val = train_proc_sorted.loc[mask_val, feature_cols]\n",
        "y_val = train_proc_sorted.loc[mask_val, \"demand\"].astype(float)\n",
        "\n",
        "y_tr_log = np.log1p(y_tr)\n",
        "y_val_log = np.log1p(y_val)\n",
        "y_all_log = np.log1p(y_all)"
      ],
      "metadata": {
        "id": "dWqBZvBKEHgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_params = {\n",
        "    \"objective\": \"regression\",\n",
        "    \"learning_rate\": 0.04,\n",
        "    \"n_estimators\": 2000,\n",
        "    \"num_leaves\": 80,\n",
        "    \"min_data_in_leaf\": 20,\n",
        "    \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.8,\n",
        "    \"bagging_freq\": 4,\n",
        "    \"lambda_l1\": 0.1,\n",
        "    \"lambda_l2\": 0.2,\n",
        "    \"random_state\": RANDOM_STATE,\n",
        "}\n",
        "\n",
        "lgb_model = LGBMRegressor(**lgb_params)\n",
        "\n",
        "print(\"Training LightGBM...\")\n",
        "lgb_model.fit(X_tr, y_tr_log)\n",
        "print(\"LightGBM training done.\")\n",
        "\n",
        "val_pred_log = lgb_model.predict(X_val)\n",
        "val_pred = np.expm1(val_pred_log)\n",
        "\n",
        "val_mae = mean_absolute_error(y_val, val_pred)\n",
        "val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
        "\n",
        "print(f\"[LGBM] Validation MAE:  {val_mae:.3f}\")\n",
        "print(f\"[LGBM] Validation RMSE: {val_rmse:.3f}\")"
      ],
      "metadata": {
        "id": "z0T_NWkQEJKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_final = LGBMRegressor(**lgb_params)\n",
        "print(\"Training final LGBM on full train...\")\n",
        "lgb_final.fit(X_all, y_all_log)\n",
        "print(\"Final training done.\")"
      ],
      "metadata": {
        "id": "O_zMdC4_ELn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_proc[feature_cols].copy()\n",
        "test_pred_log = lgb_final.predict(X_test)\n",
        "test_pred = np.expm1(test_pred_log)\n",
        "\n",
        "prod_q = train_proc.groupby(\"product_rk\")[\"demand\"].quantile(0.995).to_dict()\n",
        "prod_upper = (\n",
        "    test_proc[\"product_rk\"]\n",
        "    .map(prod_q)\n",
        "    .fillna(train_proc[\"demand\"].quantile(0.99))\n",
        "    .values\n",
        ")\n",
        "test_pred = np.minimum(test_pred, prod_upper)\n",
        "\n",
        "short_mask = test_proc[\"series_count\"].fillna(0) < 2\n",
        "test_pred[short_mask.values] = (\n",
        "    test_proc.loc[short_mask, \"prod_median\"]\n",
        "    .fillna(global_med)\n",
        "    .values\n",
        ")\n",
        "\n",
        "test_pred = np.maximum(0, test_pred)\n",
        "test_pred = np.round(test_pred).astype(int)"
      ],
      "metadata": {
        "id": "0X7VynFoENNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = test_proc[[\"id\"]].copy().reset_index(drop=True)\n",
        "submission[\"predicted\"] = test_pred\n",
        "\n",
        "submission = sample[[\"id\"]].merge(submission, on=\"id\", how=\"left\")\n",
        "submission[\"predicted\"] = (\n",
        "    submission[\"predicted\"].fillna(global_med).astype(int)\n",
        ")\n",
        "\n",
        "out_path = DATA_DIR / \"submission_lgb_final.csv\"\n",
        "submission.to_csv(out_path, index=False)\n",
        "print(\"Saved:\", out_path)\n",
        "print(submission.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ_2UrHXA19p",
        "outputId": "629473e8-03d9-4d9d-a2cc-339708d929be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (35344, 11)\n",
            "Test shape: (1404, 5)\n",
            "Processed: train rows 34144, test rows 1200\n",
            "Training LightGBM...\n",
            "LightGBM training done.\n",
            "[LGBM] Validation MAE:  4.591\n",
            "[LGBM] Validation RMSE: 7.569\n",
            "Training final LGBM on full train...\n",
            "Final training done.\n",
            "Saved: submission_lgb_final.csv\n",
            "    id  predicted\n",
            "0  908          6\n",
            "1  909          8\n",
            "2  910          5\n",
            "3  911          3\n",
            "4  912          2\n"
          ]
        }
      ]
    }
  ]
}